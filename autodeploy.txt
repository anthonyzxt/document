#自动化部署
- 环境的规划
	- 开发环境  
	    >开发者自己的环境，这个需要运维设置的开发环境，大家共用
	- 测试环境  
	    >功能测试环境和性能测试环境
	- 预生产环境  
		>生产环境集群中的某一个节点担任。  
		>产生的原因：数据库不一致;使用生产环境的联调接口，如：支付接口
	- 生产环境  
		>直接对用户提供服务的环境
##构建自动化部署的规划
1. 规划
2. 实现
3. 总结和扩展
###1. 规划
1. 集群有10个节点
	1. 实现一键部署10个节点
	2. 一键回滚到任意版本
	3. 一键回滚到上个版本
2. 部署
	1. git svn
	2. 代码的获取
		- svn+git直接拉取某个分支
		- svn:指定版本号
		- git:指定tag
	3. 差异解决
		1. 各个节点有差异，配置文件不一样，crontab.xml 预生产节点
		2. 代码仓库和实际的差异。配置文件是否在代码仓库中。配置文件只在部署上有，单独的项目
	4. 如何更新。Java tomcat需要更新
	5. 测试
	6. 串行和并行
		1. 分组 `salt -b`
	7. 如何执行
		1. shell ./执行
		2. web界面
###2. 流程设计
1. 获取代码（直接拉取）
2. 编译（可选）
3. 配置文件放进去
4. 打包
5. scp到目标服务器
6. 将目标服务器移除集群
7. 解压
8. 放置到webroot
9. scp差异文件
10. 重启（可选）
11. 测试
12. 加入集群
###3. 实现的shell函数
- 关于uuid
	blkid 文件
- 关于自动部署问题
	- 是否多人执行：加入锁文件
	- 记录执行日志
- 代码部分(基于shell)
	<pre># cat deploy.sh   
	#!/bin/bash
	#Node list
	Pre_list="172.16.1.160"
	Group_list1="172.16.1.171"
	#Date/Time variable
	CDate=$(date "+%Y-%m-%d")
	CTime=$(date "+%H-%M-%S")
	
	Log_Date='date "+%Y-%m-%d"'
	Log_Time='date "+%H-%M-%S"'
	
	#shell env
	Shell_name="deploy.sh"
	Shell_dir="/home/www"
	Shell_log="${Shell_dir}/${Shell_name}.log"
	
	#code env
	Pro_name="web-demo"
	Code_dir="/deploy/code/web-demo"
	Config_dir="/deploy/config"
	Tmp_dir="/deploy/tmp"
	Tar_dir="/deploy/tar"
	Lock_file="/var/run/deploy.lock"
	
	usage(){
	  echo "Usage: $0 {deploy | rollback}"
	}
	
	writelog(){
	  LOGINFO=$1
	  echo "${CDate}${CTime}: ${Shell_name}: ${LOGINFO} ">>${Shell_log}
	}
	shell_lock(){
	  touch ${Lock_file}
	}
	
	shell_unlock(){
	  rm -f ${Lock_file}
	}
	code_get(){
	  writelog "code_get"
	  cd ${Code_dir} && git pull
	  cp -r ${Code_dir} ${Tmp_dir}/
	  Api_verL=$(git show|grep commit|cut -d ' ' -f2)
	  Api_ver=$(echo ${Api_verL}:0:6})
	}
	code_build(){
	  echo code_build
	}
	
	code_config(){
	  echo code_config
	  /bin/cp -r ${Config_dir}/* ${Tmp_dir}/${Pro_name}
	  Pkg_name=${Pro_name}_${Api_ver}_${CDate}_${CTime}
	  cd ${Tmp_dir} && mv ${Pro_name} ${Pkg_name}
	}
	
	code_tar(){
	  writelog "code_tar"
	  cd ${Tmp_dir} && tar czf ${Pkg_name}.tar.gz ${Pkg_name}
	  writelog "${Pkg_name}"
	}
	
	code_scp(){
	  writelog code_scp
	  for node in $Pre_list;do
	    scp ${Tmp_dir}/${Pkg_name}.tar.gz $node:/opt/webroot/
	  done
	  
	  for node in $Group_list1;do
	    scp ${Tmp_dir}/${Pkg_name}.tar.gz $node:/opt/webroot/
	  done
	}
	
	code_node_remove(){
	  writelog cluster_node_remove
	}
	
	pre_deploy(){
	  writelog "remove from cluster"
	  ssh $Pre_list "cd /opt/webroot && tar zxf ${Pkg_name}.tar.gz"
	  ssh $Pre_list "rm -f /webroot/web-demo && ln -s /opt/webroot/{Pkg_name} /webroot/web-demo"
	}
	
	url_test(){
	  URL=$1
	  curl -s --head $URL | grep '200 OK'
	  if [ $? -ne 0 ];then
	    shell_unlock;
	    writelog "test error" && exit
	  fi
	}
	
	pre_test(){
	  url_test "http ://10.0.0.160/index.html"
	  echo "add to cluster"
	}
	
	group1_deploy(){
	  writelog code_deploy
	  for node in $Group_list2;do
	    ssh $node "cd /opt/webroot && tar zxf ${Pkg_name}.tar.gz"
	    ssh $node "rm -f /webroot/web-demo && ln -s /opt/webroot/{Pkg_name} /webroot/web-demo"
	  done
	  scp ${Config_dir}/other/10.0.0.171.crontab.xml 10.0.0.171:/webroot/web-demo/crontab.xml
	}
	
	group1_test(){
	  url_test "http ://10.0.0.171/index.html"
	  echo "add to cluster"
	}
	
	#code_node_in(){
	#  echo code_node_in
	#}
	
	rollback(){
	  echo rollback
	}
	main(){
	  if [ -f ${Lock_file} ];then
	     echo "deploy is running..."
	     exit
	  fi
	  Deploy_Method=$1
	  case ${Deploy_Method} in
	    deploy)
	        shell_lock;
	        code_get;
	        code_buld;
	        code_config;
	        code_tar;
	        code_scp;
	        #code_node_remove;
	        group1_deploy;
	        group1_test;
	        #code_diff;
	        group2_deploy;
	        code_test;
	        code_node_in;
	        shell_unlock;
	        ;; 
	    rollback)
	        shell_lock;
	        rollback;
	        shell_unlock;
	        ;;
	    *)
	        usage;
	  esac
	}
	main $1
	</pre>
- 关于回滚流程
	- 1. 列出回滚可用版本
	- 2. 目标移除集群
	- 3. 执行回滚
	- 4. 重启测试
	- 5. 加入集群
	>还有个紧急流程
    	>1.列出回滚版本
    	>2.执行回滚（重启）
    	>还有非常紧急情况，直接回滚上一版本
###4.更新说明
- git pull
	>频繁更新
- git tag
	>稳定更新
- 获取指定的commit id
	- master分支，可作为发布的版本
	- dev分支
- 安装 
###5.devops
- 什么是devops
	>- DevOps（英文Development和Operations的组合）是一组过程、方法与系统的统称，用于促进开发（应用程序/软件工程）、技术运营和质量保障（QA）部门之间的沟通、协作与整合。它的出现是由于软件行业日益清晰地认识到：为了按时交付软件产品和服务，开发和运营工作必须紧密合作。    
	>- 也是一种文化，让开发、运维、测试之间沟通的一种文化。  
	>- 目的是一样的，为了让我们的在软件构建、测试、发布更加的敏捷、频繁、可靠。
- 持续集成
	>是指在软件开发过程中，频繁地将代码集成到主干上，然后进行**自动化测试**
	>![](https://www.unixhot.com/uploads/article/20160813/95dc642c4c4230e9c1b418cb00f4e5d4.png)
- 持续交付
	>是指在持续集成的基础上，将集成后的代码部署到更贴近真实运行环境的「类生产环境」（production-like environments）中
	>![](https://www.unixhot.com/uploads/article/20160813/95dc642c4c4230e9c1b418cb00f4e5d4.png)
- 持续部署
	> 在持续交付的基础上，把部署到生产环境的过程自动化。如果你对比上图持续部署就可以发现持续部署和持续交付的区别就是最终部署到生产环境是自动化的。
	> ![](https://www.unixhot.com/uploads/article/20160813/b15dd230dd7b351a1cce50257cb15589.png)
###6. 持续集成之Jenkins安装部署
- 安装JDK  
	`yum install -y java-1.8.0`
- 安装Jekins
	<pre>cd /etc/yum.repos.d/
	wget http://pkg.jenkins.io/redhat/jenkins.repo
	rpm --import http://pkg.jenkins.io/redhat/jenkins.io.key
	yum install -y jenkins
	systemctl start jenkins</pre>
- 访问Jenkins
	>在浏览器输入http://ip:8080来访问jenkins。解锁Jenkins，请在/var/lib/jenkins/secrets/initialAdminPassword中查看文件。
	`cat /var/lib/jenkins/secrets/initialAdminPassword` 
- 一些基本操作
	- gitlab修改ssh_port
		<pre>vi /etc/gitlab/gitlab.rb
		vi /opt/gitlab/embedded/service/gitlab-rails/config/gitlab.yml
		gitlab-ctl reconfigure
		gitlab-ctl restart</pre>
	- 认证
		- gitlab端加入deploy key(public key)
		- jenkins加入(private key)
	- 指定提取分支
		- gitlab ssh地址 
###7. 持续代码质量管理-Sonar部署
> Sonar 是一个用于代码质量管理的开放平台。通过插件机制，Sonar 可以集成不同的测试工具，代码分析工具，以及持续集成工具。与持续集成工具（例如 Hudson/Jenkins 等）不同，Sonar 并不是简单地把不同的代码检查工具结果（例如 FindBugs，PMD 等）直接显示在 Web 页面上，而是通过不同的插件对这些结果进行再加工处理，通过量化的方式度量代码质量的变化，从而可以方便地对不同规模和种类的工程进行代码质量管理。
在对其他工具的支持方面，Sonar 不仅提供了对 IDE 的支持，可以在 Eclipse 和 IntelliJ IDEA 这些工具里联机查看结果；同时 Sonar 还对大量的持续集成工具提供了接口支持，可以很方便地在持续集成中使用 Sonar。
此外，Sonar 的插件还可以对 Java 以外的其他编程语言提供支持，对国际化以及报告文档化也有良好的支持

- 部署
	>Sonar的相关下载和文档可以在下面的链接中找到：http://www.sonarqube.org/downloads/。需要注意最新版的Sonar需要至少JDK 1.8及以上版本。
	<pre>yum install -y java-1.8.0
	cd /usr/local/src
	wget https://sonarsource.bintray.com/Distribution/sonarqube/sonarqube-5.6.zip
	unzip sonarqube-5.6.zip
	mv sonarqube-5.6 /usr/local/
	ln -s /usr/local/sonarqube-5.6/ /usr/local/sonarqube</pre>
- 准备Sonar数据库
	>数据库要求：mysql需要5.6以上 安装最新版本的sonar
	>数据库建库及授权
		<pre>mysql> CREATE DATABASE sonar CHARACTER SET utf8 COLLATE utf8_general_ci;
	mysql> GRANT ALL ON sonar.* TO 'sonar'@'localhost' IDENTIFIED BY 'sonar@pw';
	mysql> GRANT ALL ON sonar.* TO 'sonar'@'%' IDENTIFIED BY 'sonar@pw';
	mysql> FLUSH PRIVILEGES;</pre>
- 安装sonar
	<pre>yum install -y java-1.8.0
	cd /usr/local/src
	wget https://sonarsource.bintray.com/Distribution/sonarqube/sonarqube-5.6.zip
	unzip sonarqube-5.6.zip
	mv sonarqube-5.6 /usr/local/
	ln -s /usr/local/sonarqube-5.6/ /usr/local/sonarqube	</pre>
- 配置
	<pre>cd /usr/local/sonarqube/conf/
	vim sonar.properties
	sonar.jdbc.username=sonar
	sonar.jdbc.password=sonae@pw
	sonar.jdbc.url=jdbc:mysql://localhost:3306/sonar?useUnicode=true&characterEncoding=utf8&rewriteBatchedStatements=true&useConfigs=maxPerformance</pre>
	>其他：  
	>配置Java访问数据库驱动(可选)
    默认情况Sonar有自带的嵌入的数据库，那么你如果使用类是Oracle数据库，必须手动复制驱动类到${SONAR_HOME}/extensions/jdbc-driver/oracle/目录下，其它支持的数据库默认提供了驱动。其它数据库的配置可以参考官方文档：
	http://docs.sonarqube.org/display/HOME/SonarQube+Platform
- 启动
	>这个自己看情况修改
	<pre> vim sonar.properties
	sonar.web.host=0.0.0.0
	sonar.web.port=9000
	/usr/local/sonarqube/bin/linux-x86-64/sonar.sh start
	访问： http://IP:9000</pre>
- 插件安装的两种方法
	- web界面安装更新
	- 放在服务器端软件目录下
		>/usr/local/sonarqube/extensions/plugins
	- 中文包安装
		- administrator - system - update center - available - search - chinese。然后根据要求选择相应的语言包插件

- 分析插件的安装：Scaner
	[http://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner](http://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner)
	- 安装
	<pre>cd /usr/local/src/
	wget https://sonarsource.bintray.com/Distribution/sonar-scanner-cli/sonar-scanner-2.8.zip
	unzip sonar-scanner-2.8.zip 
	mv sonar-scanner-2.8 /usr/local/
	ln -s /usr/local/sonar-scanner-2.8/ /usr/local/sonar-scanner</pre>
	- 配置
		<pre>cd /usr/local/sonar-scanner/conf
		# grep -vE '#|^$' sonar-scanner.properties 
		sonar.host.url=http://localhost:9000

		sonar.sourceEncoding=UTF-8

		sonar.jdbc.username=sonar
		sonar.jdbc.password=sonar@pw

		sonar.jdbc.url=jdbc:mysql://localhost:3306/sonar?useUnicode=true&amp;characterEncoding=utf8</pre>
		>sonar-scaner要与jenkins放在同一个服务器上。然后修改相关的属性配置。
	- 质量分析测试
		>从sonarsouce/sonar-example测试代码，这里以php为例
		<pre>cd /tools/sonar-examples-master/projects/languages/php/php-sonar-runner
		#执行测试
		/usr/local/sonar-scanner/bin/sonar-scanner</pre>
- sonar与jenkins的结合
	>jenkins安装 `sonarqube plugin` 插件
	- 设置
		- 1. 系统管理 - 系统设置 - 添加sonar
		- 2. 系统管理 - `global tool configuration` - 新增`SonarQube Scanner`和路径
		- 3. 修改项目配置，增加构建步骤，选择`sonar...scaner`，添加扫描属性设置(Analysis properties)<pre>sonar.projectKey=demo
		sonar.projectName=demo
		sonar.projectVersion=1.0
		sonar.sources=./
		sonar.language=php
		sonar.sourceEncoding=UTF-8</pre>
- 代码部署
	- 可以调用shell脚本执行
	- 写在jenkins里边执行，和代码质量检查分开执行
	- 示例
		- 直接新增一个项目，点击构建，输入自动构建的shell命令即可，注意权限:**加入sudoers(jenkins ALL=（ALL） NOPASSWD: /usr/bin/ssh)和关闭tty接口（即远程执行部分）**
		<pre>sudo ssh www@10.0.0.31 "sh autodeploy deploy"</pre>
	- 项目关联（parametenzed trigger plugin关联插件）
		>即构建后操作
	- Pipeline插件（Build Pipeline Plugin）
		>新增视图，主要选择`Select Initial Job`，即从哪个开始执行，自动执行
- jenkins与gitlab集成(webhook)
	>`gitlab hook plugin` 和 `gitlab plugin`以及验证插件`Build Authorization Token Root Plugin`
	- 配置的两种方法
		- 在构建的时候设置
	- token的生成
		<pre>openssl rand -hex 10</pre> 
	- 添加token
		1. 项目编辑到构建触发器-身份验证令牌：填入令牌
		2. 勾选: **Build when a change is pushed to GitLab. GitLab CI Service URL: http://10.0.0.160:8080/project/web-demo**
		3. gitlab里边添加钩子脚本，选择要添加的项目：点击右上角设置里边的**webhooks**,令牌模式：**buildByToken/build?job=RevolutionTest&token=TacoTuesday**。修改如下：http://10.0.0.160:8080/buildByToken/build?job=demo-sonar&token=TacoTuesday。任何粘贴在webhook里的URL地址栏，保存即可
		4. 剩下的只要提交便可部署测试环境，会自动